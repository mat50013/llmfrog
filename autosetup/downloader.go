package autosetup

import (
	"archive/zip"
	"bufio"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"os"
	"os/exec"
	"path/filepath"
	"runtime"
	"strconv"
	"strings"
	"time"
)

// SystemInfo contains information about the current system
type SystemInfo struct {
	OS           string
	Architecture string
	HasCUDA      bool
	HasROCm      bool
	HasVulkan    bool
	HasMetal     bool
	// Extended system information
	CPUCores      int
	PhysicalCores int
	TotalRAMGB    float64
	CUDAVersion   string
	ROCmVersion   string
	VRAMDetails   []GPUInfo
	TotalVRAMGB   float64
	HasMLX        bool
	HasIntel      bool
}

// GPUInfo contains information about individual GPUs
type GPUInfo struct {
	Name     string
	VRAMGB   float64
	Type     string // "CUDA", "ROCm", "MLX", "Intel"
	DeviceID int
}

// BinaryInfo contains information about the downloaded binary
type BinaryInfo struct {
	Path    string
	Version string
	Type    string // "cpu", "cuda", "rocm", "vulkan", "metal"
}

// BinaryMetadata stores information about the currently installed binary
type BinaryMetadata struct {
	Type    string `json:"type"`
	Version string `json:"version"`
	Path    string `json:"path"`
}

// GitHubRelease represents a GitHub release response
type GitHubRelease struct {
	TagName    string `json:"tag_name"`
	Name       string `json:"name"`
	Draft      bool   `json:"draft"`
	Prerelease bool   `json:"prerelease"`
	CreatedAt  string `json:"created_at"`
	Assets     []struct {
		Name               string `json:"name"`
		BrowserDownloadURL string `json:"browser_download_url"`
	} `json:"assets"`
}

const (
	LLAMA_CPP_GITHUB_API      = "https://api.github.com/repos/ggml-org/llama.cpp/releases/latest"
	LLAMA_CPP_CURRENT_VERSION = "b6527" // Fallback version
	BINARY_METADATA_FILE      = "binary_metadata.json"
)

// GetLatestReleaseVersion fetches the latest llama.cpp release version from GitHub
func GetLatestReleaseVersion() (string, error) {
	fmt.Printf("üîç Checking for latest llama.cpp release...\n")

	client := &http.Client{
		Timeout: 10 * time.Second,
	}

	resp, err := client.Get(LLAMA_CPP_GITHUB_API)
	if err != nil {
		fmt.Printf("‚ö†Ô∏è  Failed to check latest release, using fallback version %s\n", LLAMA_CPP_CURRENT_VERSION)
		return LLAMA_CPP_CURRENT_VERSION, nil
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		fmt.Printf("‚ö†Ô∏è  GitHub API returned %d, using fallback version %s\n", resp.StatusCode, LLAMA_CPP_CURRENT_VERSION)
		return LLAMA_CPP_CURRENT_VERSION, nil
	}

	var release GitHubRelease
	if err := json.NewDecoder(resp.Body).Decode(&release); err != nil {
		fmt.Printf("‚ö†Ô∏è  Failed to parse release info, using fallback version %s\n", LLAMA_CPP_CURRENT_VERSION)
		return LLAMA_CPP_CURRENT_VERSION, nil
	}

	// Validate the tag name format (should be like "b6527" or "v1.0.0")
	version := release.TagName
	if version == "" {
		fmt.Printf("‚ö†Ô∏è  Empty version tag, using fallback version %s\n", LLAMA_CPP_CURRENT_VERSION)
		return LLAMA_CPP_CURRENT_VERSION, nil
	}

	fmt.Printf("‚úÖ Latest release found: %s\n", version)
	return version, nil
}

// saveBinaryMetadata saves information about the installed binary
func saveBinaryMetadata(extractDir string, binaryInfo *BinaryInfo) error {
	metadata := BinaryMetadata{
		Type:    binaryInfo.Type,
		Version: binaryInfo.Version,
		Path:    binaryInfo.Path,
	}

	metadataPath := filepath.Join(extractDir, BINARY_METADATA_FILE)
	file, err := os.Create(metadataPath)
	if err != nil {
		return fmt.Errorf("failed to create metadata file: %v", err)
	}
	defer file.Close()

	encoder := json.NewEncoder(file)
	encoder.SetIndent("", "  ")
	return encoder.Encode(metadata)
}

// LoadBinaryMetadata loads information about the currently installed binary
func LoadBinaryMetadata(extractDir string) (*BinaryMetadata, error) {
	metadataPath := filepath.Join(extractDir, BINARY_METADATA_FILE)
	file, err := os.Open(metadataPath)
	if err != nil {
		return nil, err // File doesn't exist or can't be read
	}
	defer file.Close()

	var metadata BinaryMetadata
	decoder := json.NewDecoder(file)
	err = decoder.Decode(&metadata)
	if err != nil {
		return nil, fmt.Errorf("failed to decode metadata: %v", err)
	}

	return &metadata, nil
}

// DetectSystem detects the current system capabilities
func DetectSystem() SystemInfo {
	system := SystemInfo{
		OS:           runtime.GOOS,
		Architecture: runtime.GOARCH,
	}

	// Detect GPU capabilities
	system.HasCUDA = detectCUDA()
	system.HasROCm = detectROCm()
	system.HasVulkan = detectVulkan()
	system.HasMetal = detectMetal()

	// Detect GPU VRAM if we have GPU support
	if system.HasCUDA || system.HasROCm || system.HasVulkan || system.HasMetal {
		gpuInfo, err := DetectAllGPUs()
		if err == nil && gpuInfo.TotalMemory > 0 {
			system.TotalVRAMGB = gpuInfo.TotalMemory
		}
	}

	// Get system RAM
	system.TotalRAMGB = getSystemRAM()

	return system
}

// checkBinaryExists checks if a binary URL exists on GitHub
func checkBinaryExists(url string) bool {
	client := &http.Client{
		Timeout: 10 * time.Second,
	}

	req, err := http.NewRequest("HEAD", url, nil)
	if err != nil {
		return false
	}

	resp, err := client.Do(req)
	if err != nil {
		return false
	}
	defer resp.Body.Close()

	return resp.StatusCode == http.StatusOK || resp.StatusCode == http.StatusFound
}

// GetOptimalBinaryURL returns the best binary download URL for the system with fallback support
func GetOptimalBinaryURL(system SystemInfo, forceBackend string, version string) (string, string, error) {
	var filename, binaryType string
	var fallbackTypes []string

	// If version is empty, get the latest version
	if version == "" {
		var err error
		version, err = GetLatestReleaseVersion()
		if err != nil {
			version = LLAMA_CPP_CURRENT_VERSION
		}
	}

	// If a backend is forced, use that instead of auto-detection
	if forceBackend != "" {
		binaryType = forceBackend
		fmt.Printf("üéØ Using forced backend: %s\n", forceBackend)
	} else {
		// Auto-detect best backend for the system and set fallbacks
		switch system.OS {
		case "windows":
			// Windows: CUDA > ROCm > Vulkan > CPU
			if system.HasCUDA {
				binaryType = "cuda"
				fallbackTypes = []string{"vulkan", "cpu"}
			} else if system.HasROCm {
				binaryType = "rocm"
				fallbackTypes = []string{"vulkan", "cpu"}
			} else if system.HasVulkan {
				binaryType = "vulkan"
				fallbackTypes = []string{"cpu"}
			} else {
				binaryType = "cpu"
			}
		case "linux":
			// Linux: Check for CUDA, ROCm, Vulkan, then CPU
			if system.HasCUDA {
				fmt.Printf("   üê∏ CUDA detected! Attempting CUDA backend for maximum GPU performance\n")
				binaryType = "cuda"
				fallbackTypes = []string{"vulkan", "cpu"}
			} else if system.HasROCm {
				fmt.Printf("   üê∏ ROCm detected! Using ROCm backend for AMD GPUs\n")
				binaryType = "rocm"
				fallbackTypes = []string{"vulkan", "cpu"}
			} else if system.HasVulkan {
				fmt.Printf("   üê∏ Vulkan detected! Using Vulkan backend\n")
				binaryType = "vulkan"
				fallbackTypes = []string{"cpu"}
			} else {
				fmt.Printf("   üê∏ No GPU detected, using CPU backend\n")
				binaryType = "cpu"
			}
		case "darwin":
			// macOS: Metal (Apple Silicon) > CPU (Intel)
			if system.Architecture == "arm64" {
				binaryType = "metal"
			} else {
				binaryType = "cpu"
			}
		default:
			return "", "", fmt.Errorf("unsupported operating system: %s", system.OS)
		}
	}

	// Now determine the filename based on the chosen backend and version
	switch system.OS {
	case "windows":
		switch binaryType {
		case "cuda":
			filename = fmt.Sprintf("llama-%s-bin-win-cuda-12.4-x64.zip", version)
		case "rocm":
			filename = fmt.Sprintf("llama-%s-bin-win-rocm-x64.zip", version)
		case "vulkan":
			filename = fmt.Sprintf("llama-%s-bin-win-vulkan-x64.zip", version)
		case "cpu":
			filename = fmt.Sprintf("llama-%s-bin-win-cpu-x64.zip", version)
		default:
			return "", "", fmt.Errorf("unsupported backend '%s' for Windows", binaryType)
		}
	case "linux":
		switch binaryType {
		case "cuda":
			// Try CUDA-specific binary first
			filename = fmt.Sprintf("llama-%s-bin-ubuntu-x64-cuda.zip", version)
			fmt.Printf("   üê∏ Attempting to download CUDA-enabled binary for GPU acceleration\n")
		case "vulkan":
			// Try Vulkan-specific binary
			filename = fmt.Sprintf("llama-%s-bin-ubuntu-x64-vulkan.zip", version)
			fmt.Printf("   üê∏ Downloading Vulkan-enabled binary for GPU acceleration\n")
		case "rocm":
			// Try ROCm-specific binary
			filename = fmt.Sprintf("llama-%s-bin-ubuntu-x64-rocm.zip", version)
			fmt.Printf("   üê∏ Downloading ROCm-enabled binary for AMD GPUs\n")
		case "cpu":
			// CPU-only binary
			filename = fmt.Sprintf("llama-%s-bin-ubuntu-x64.zip", version)
			fmt.Printf("   üê∏ Downloading CPU-only binary\n")
		default:
			return "", "", fmt.Errorf("unsupported backend '%s' for Linux", binaryType)
		}
	case "darwin":
		switch binaryType {
		case "metal":
			filename = fmt.Sprintf("llama-%s-bin-macos-arm64.zip", version)
		case "cpu":
			if system.Architecture == "arm64" {
				filename = fmt.Sprintf("llama-%s-bin-macos-arm64.zip", version)
			} else {
				filename = fmt.Sprintf("llama-%s-bin-macos-x64.zip", version)
			}
		default:
			return "", "", fmt.Errorf("unsupported backend '%s' for macOS", binaryType)
		}
	default:
		return "", "", fmt.Errorf("unsupported operating system: %s", system.OS)
	}

	downloadBase := fmt.Sprintf("https://github.com/ggml-org/llama.cpp/releases/download/%s", version)
	url := fmt.Sprintf("%s/%s", downloadBase, filename)

	// Check if the primary binary exists
	if binaryType == "cuda" || binaryType == "vulkan" || binaryType == "rocm" {
		fmt.Printf("   üîç Checking if %s binary is available...\n", binaryType)
		if !checkBinaryExists(url) {
			fmt.Printf("   ‚ö†Ô∏è  %s binary not available in release %s\n", binaryType, version)

			// Try fallbacks for Linux
			if system.OS == "linux" && len(fallbackTypes) > 0 {
				for _, fallback := range fallbackTypes {
					fmt.Printf("   üîÑ Trying fallback: %s...\n", fallback)
					var fallbackFilename string
					switch fallback {
					case "vulkan":
						fallbackFilename = fmt.Sprintf("llama-%s-bin-ubuntu-x64-vulkan.zip", version)
					case "cpu":
						fallbackFilename = fmt.Sprintf("llama-%s-bin-ubuntu-x64.zip", version)
					}
					fallbackURL := fmt.Sprintf("%s/%s", downloadBase, fallbackFilename)
					if checkBinaryExists(fallbackURL) {
						fmt.Printf("   ‚úÖ Using %s binary as fallback\n", fallback)
						if fallback == "vulkan" && binaryType == "cuda" {
							fmt.Printf("   üê∏ Vulkan will still provide GPU acceleration\n")
						}
						return fallbackURL, fallback, nil
					}
					fmt.Printf("   ‚ùå %s binary also not available\n", fallback)
				}
			}
		} else {
			fmt.Printf("   ‚úÖ %s binary found!\n", binaryType)
			if binaryType == "cuda" {
				fmt.Printf("   üê∏ Using CUDA-enabled binary for maximum GPU acceleration\n")
			}
		}
	}

	return url, binaryType, nil
}

// removeDirectoryRobust attempts to remove a directory with retry logic for Windows file locking issues
func removeDirectoryRobust(dir string) error {
	// First, try to kill any running llama-server processes
	if runtime.GOOS == "windows" {
		killLlamaServerProcesses()
	}

	maxRetries := 5
	retryDelay := 500 * time.Millisecond

	for attempt := 0; attempt < maxRetries; attempt++ {
		err := os.RemoveAll(dir)
		if err == nil {
			return nil
		}

		// If it's not a permission error, don't retry
		if !strings.Contains(err.Error(), "Access is denied") &&
			!strings.Contains(err.Error(), "being used by another process") {
			return err
		}

		if attempt < maxRetries-1 {
			fmt.Printf("‚è≥ Retry %d/%d: Waiting for file handles to be released...\n", attempt+1, maxRetries)
			time.Sleep(retryDelay)
			retryDelay *= 2 // Exponential backoff
		}
	}

	return fmt.Errorf("failed to remove directory after %d attempts", maxRetries)
}

// killLlamaServerProcesses kills any running llama-server processes on Windows
func killLlamaServerProcesses() {
	if runtime.GOOS != "windows" {
		return
	}

	// Only kill llama-server.exe processes, not frogllm.exe
	cmd := exec.Command("taskkill", "/F", "/IM", "llama-server.exe")
	err := cmd.Run()
	if err == nil {
		fmt.Printf("üîÑ Terminated running llama-server processes\n")
	}

	// Give a moment for cleanup
	time.Sleep(200 * time.Millisecond)
}

// DownloadBinary downloads and extracts the llama-server binary
func DownloadBinary(downloadDir string, system SystemInfo, forceBackend string) (*BinaryInfo, error) {
	// Get the latest version
	version, err := GetLatestReleaseVersion()
	if err != nil {
		version = LLAMA_CPP_CURRENT_VERSION
	}

	url, binaryType, err := GetOptimalBinaryURL(system, forceBackend, version)
	if err != nil {
		return nil, err
	}

	// Create download directory
	err = os.MkdirAll(downloadDir, 0755)
	if err != nil {
		return nil, fmt.Errorf("failed to create download directory: %v", err)
	}

	// Track the actual binary type (may change due to fallback)
	actualBinaryType := binaryType

	extractDir := filepath.Join(downloadDir, "llama-server")

	// Check if binary already exists
	fmt.Printf("üîç Checking for existing binary in: %s\n", extractDir)
	existingServerPath, err := FindLlamaServer(extractDir)
	if err == nil {
		// Binary exists, check if it's the right type and version
		fmt.Printf("‚úÖ Found existing llama-server binary: %s\n", existingServerPath)

		// Check metadata to see if the existing binary matches the required type and version
		metadata, metaErr := LoadBinaryMetadata(extractDir)
		if metaErr == nil && metadata.Type == binaryType && metadata.Version == version {
			// Binary type and version match, check for additional requirements
			if system.HasCUDA && system.OS == "windows" {
				cudartPath := filepath.Join(extractDir, "cudart64_12.dll")
				if _, err := os.Stat(cudartPath); err == nil {
					fmt.Printf("‚úÖ Existing %s binary (v%s) is compatible, skipping download\n", binaryType, version)
					return &BinaryInfo{
						Path:    existingServerPath,
						Version: version,
						Type:    actualBinaryType,
					}, nil
				} else {
					fmt.Printf("‚ö†Ô∏è  CUDA runtime missing, will download both runtime and binary\n")
				}
			} else {
				// Non-CUDA system or metadata matches, existing binary is sufficient
				fmt.Printf("‚úÖ Existing %s binary (v%s) is compatible, skipping download\n", binaryType, version)
				return &BinaryInfo{
					Path:    existingServerPath,
					Version: version,
					Type:    actualBinaryType,
				}, nil
			}
		} else {
			// Binary type doesn't match, version is outdated, or no metadata - need to re-download
			if metaErr == nil {
				if metadata.Version != version {
					fmt.Printf("üîÑ Version update available: %s -> %s. Re-downloading...\n", metadata.Version, version)
				} else {
					fmt.Printf("üîÑ Binary type mismatch: existing=%s, required=%s. Re-downloading...\n", metadata.Type, binaryType)
				}
			} else {
				fmt.Printf("üîÑ No binary metadata found. Re-downloading %s binary (v%s)...\n", binaryType, version)
			}

			// Remove existing binary directory to ensure clean installation
			err = removeDirectoryRobust(extractDir)
			if err != nil {
				fmt.Printf("‚ö†Ô∏è  Failed to remove existing binary directory: %v\n", err)
				fmt.Printf("üí° This can happen if binary files are locked by Windows.\n")
				fmt.Printf("   Try:\n")
				fmt.Printf("   1. Restart FrogLLM\n")
				fmt.Printf("   2. Wait a few seconds and try again\n")
				fmt.Printf("   3. Manually delete the 'binaries' folder if needed\n")
				// Continue with download anyway - it might still work
			} else {
				fmt.Printf("üóëÔ∏è  Removed existing binary directory\n")
			}
		}
	}

	// If we get here, we need to download
	fmt.Printf("‚¨áÔ∏è  Downloading llama-server binary (v%s)...\n", version)

	// For CUDA on Windows, download both runtime and binary
	if system.HasCUDA && system.OS == "windows" {
		cudartURL := fmt.Sprintf("https://github.com/ggml-org/llama.cpp/releases/download/%s/cudart-llama-bin-win-cuda-12.4-x64.zip", version)
		fmt.Printf("Downloading CUDA runtime from: %s\n", cudartURL)

		// Download CUDA runtime
		cudartZipPath := filepath.Join(downloadDir, "cudart.zip")
		err = downloadFile(cudartURL, cudartZipPath)
		if err != nil {
			return nil, fmt.Errorf("failed to download CUDA runtime: %v", err)
		}

		// Extract CUDA runtime
		err = extractZip(cudartZipPath, extractDir)
		if err != nil {
			return nil, fmt.Errorf("failed to extract CUDA runtime: %v", err)
		}
		os.Remove(cudartZipPath)

		fmt.Printf("Downloading llama-server (%s) from: %s\n", binaryType, url)

		// Download llama binary
		llamaZipPath := filepath.Join(downloadDir, "llama-server.zip")
		err = downloadFile(url, llamaZipPath)
		if err != nil {
			return nil, fmt.Errorf("failed to download llama binary: %v", err)
		}

		// Extract llama binary to same directory
		err = extractZip(llamaZipPath, extractDir)
		if err != nil {
			return nil, fmt.Errorf("failed to extract llama binary: %v", err)
		}
		os.Remove(llamaZipPath)
	} else {
		// Single download for non-CUDA or non-Windows
		fmt.Printf("Downloading llama-server (%s) from: %s\n", binaryType, url)

		// Download the file
		zipPath := filepath.Join(downloadDir, "llama-server.zip")
		downloadErr := downloadFile(url, zipPath)

		// If download failed with 404, try fallback options
		if downloadErr != nil && strings.Contains(downloadErr.Error(), "404") {
			fmt.Printf("‚ùå %s binary not found (404)\n", binaryType)

			// Define fallback options based on the primary type
			var fallbackTypes []string
			if binaryType == "cuda" {
				fallbackTypes = []string{"vulkan", "cpu"}
			} else if binaryType == "vulkan" {
				fallbackTypes = []string{"cpu"}
			} else if binaryType == "rocm" {
				fallbackTypes = []string{"vulkan", "cpu"}
			}

			// Try fallback options
			for _, fallback := range fallbackTypes {
				fmt.Printf("üîÑ Trying fallback: %s...\n", fallback)

				// Generate fallback URL
				var fallbackFilename string
				if system.OS == "linux" {
					switch fallback {
					case "vulkan":
						fallbackFilename = fmt.Sprintf("llama-%s-bin-ubuntu-x64-vulkan.zip", version)
					case "cpu":
						fallbackFilename = fmt.Sprintf("llama-%s-bin-ubuntu-x64.zip", version)
					}
				} else if system.OS == "windows" {
					switch fallback {
					case "vulkan":
						fallbackFilename = fmt.Sprintf("llama-%s-bin-win-vulkan-x64.zip", version)
					case "cpu":
						fallbackFilename = fmt.Sprintf("llama-%s-bin-win-cpu-x64.zip", version)
					}
				}

				if fallbackFilename == "" {
					continue
				}

				fallbackURL := fmt.Sprintf("https://github.com/ggml-org/llama.cpp/releases/download/%s/%s", version, fallbackFilename)
				fmt.Printf("   Downloading %s binary from: %s\n", fallback, fallbackURL)

				downloadErr = downloadFile(fallbackURL, zipPath)
				if downloadErr == nil {
					// Success with fallback
					fmt.Printf("‚úÖ Successfully downloaded %s binary as fallback\n", fallback)
					if fallback == "vulkan" && binaryType == "cuda" {
						fmt.Printf("üê∏ Vulkan will still provide GPU acceleration\n")
					}
					actualBinaryType = fallback
					break
				}
				fmt.Printf("   ‚ùå %s binary also not available\n", fallback)
			}
		}

		// If still failed, return error
		if downloadErr != nil {
			return nil, fmt.Errorf("failed to download binary: %v", downloadErr)
		}

		// Extract the zip file
		err = extractZip(zipPath, extractDir)
		if err != nil {
			return nil, fmt.Errorf("failed to extract binary: %v", err)
		}
		os.Remove(zipPath)
	}

	// Find the llama-server executable
	fmt.Printf("üîç Searching for llama-server executable in: %s\n", extractDir)
	serverPath, err := FindLlamaServer(extractDir)
	if err != nil {
		return nil, fmt.Errorf("failed to find llama-server executable: %v", err)
	}
	fmt.Printf("‚úÖ Found llama-server at: %s\n", serverPath)

	// Make it executable on Unix systems
	if system.OS != "windows" {
		err = os.Chmod(serverPath, 0755)
		if err != nil {
			return nil, fmt.Errorf("failed to make binary executable: %v", err)
		}
	}

	binaryInfo := &BinaryInfo{
		Path:    serverPath,
		Version: version,
		Type:    actualBinaryType,
	}

	// Save metadata about the downloaded binary
	err = saveBinaryMetadata(extractDir, binaryInfo)
	if err != nil {
		fmt.Printf("‚ö†Ô∏è  Warning: Failed to save binary metadata: %v\n", err)
		// Don't fail the entire process for metadata saving failure
	} else {
		fmt.Printf("üìù Saved binary metadata: %s type, version %s\n", actualBinaryType, version)
	}

	return binaryInfo, nil
}

// ForceDownloadBinary forces a download and re-extraction of the llama-server binary, bypassing existing files
func ForceDownloadBinary(downloadDir string, system SystemInfo, forceBackend string) (*BinaryInfo, error) {
	// Get the latest version
	version, err := GetLatestReleaseVersion()
	if err != nil {
		version = LLAMA_CPP_CURRENT_VERSION
	}

	url, binaryType, err := GetOptimalBinaryURL(system, forceBackend, version)
	if err != nil {
		return nil, err
	}

	// Create download directory
	err = os.MkdirAll(downloadDir, 0755)
	if err != nil {
		return nil, fmt.Errorf("failed to create download directory: %v", err)
	}

	extractDir := filepath.Join(downloadDir, "llama-server")

	// Force remove existing binary directory
	fmt.Printf("üóëÔ∏è  Removing existing binary directory for forced update...\n")
	err = removeDirectoryRobust(extractDir)
	if err != nil {
		fmt.Printf("‚ö†Ô∏è  Failed to remove existing binary directory: %v\n", err)
		// Continue with download anyway - it might still work
	} else {
		fmt.Printf("üóëÔ∏è  Removed existing binary directory\n")
	}

	// Track the actual binary type (may change due to fallback)
	actualBinaryType := binaryType

	// Always download fresh binary
	fmt.Printf("‚¨áÔ∏è  Force downloading llama-server binary (%s v%s)...\n", binaryType, version)

	// For CUDA on Windows, download both runtime and binary
	if system.HasCUDA && system.OS == "windows" {
		cudartURL := fmt.Sprintf("https://github.com/ggml-org/llama.cpp/releases/download/%s/cudart-llama-bin-win-cuda-12.4-x64.zip", version)
		fmt.Printf("Downloading CUDA runtime from: %s\n", cudartURL)

		// Download CUDA runtime
		cudartZipPath := filepath.Join(downloadDir, "cudart.zip")
		err = downloadFile(cudartURL, cudartZipPath)
		if err != nil {
			return nil, fmt.Errorf("failed to download CUDA runtime: %v", err)
		}

		// Extract CUDA runtime
		err = extractZip(cudartZipPath, extractDir)
		if err != nil {
			return nil, fmt.Errorf("failed to extract CUDA runtime: %v", err)
		}
		os.Remove(cudartZipPath)

		fmt.Printf("Downloading llama-server (%s) from: %s\n", binaryType, url)

		// Download llama binary
		llamaZipPath := filepath.Join(downloadDir, "llama-server.zip")
		err = downloadFile(url, llamaZipPath)
		if err != nil {
			return nil, fmt.Errorf("failed to download llama binary: %v", err)
		}

		// Extract llama binary to same directory
		err = extractZip(llamaZipPath, extractDir)
		if err != nil {
			return nil, fmt.Errorf("failed to extract llama binary: %v", err)
		}
		os.Remove(llamaZipPath)
	} else {
		// Single download for non-CUDA or non-Windows
		fmt.Printf("Downloading llama-server (%s) from: %s\n", binaryType, url)

		// Download the file
		zipPath := filepath.Join(downloadDir, "llama-server.zip")
		downloadErr := downloadFile(url, zipPath)

		// If download failed with 404, try fallback options
		if downloadErr != nil && strings.Contains(downloadErr.Error(), "404") {
			fmt.Printf("‚ùå %s binary not found (404)\n", binaryType)

			// Define fallback options based on the primary type
			var fallbackTypes []string
			if binaryType == "cuda" {
				fallbackTypes = []string{"vulkan", "cpu"}
			} else if binaryType == "vulkan" {
				fallbackTypes = []string{"cpu"}
			} else if binaryType == "rocm" {
				fallbackTypes = []string{"vulkan", "cpu"}
			}

			// Try fallback options
			for _, fallback := range fallbackTypes {
				fmt.Printf("üîÑ Trying fallback: %s...\n", fallback)

				// Generate fallback URL
				var fallbackFilename string
				if system.OS == "linux" {
					switch fallback {
					case "vulkan":
						fallbackFilename = fmt.Sprintf("llama-%s-bin-ubuntu-x64-vulkan.zip", version)
					case "cpu":
						fallbackFilename = fmt.Sprintf("llama-%s-bin-ubuntu-x64.zip", version)
					}
				} else if system.OS == "windows" {
					switch fallback {
					case "vulkan":
						fallbackFilename = fmt.Sprintf("llama-%s-bin-win-vulkan-x64.zip", version)
					case "cpu":
						fallbackFilename = fmt.Sprintf("llama-%s-bin-win-cpu-x64.zip", version)
					}
				}

				if fallbackFilename == "" {
					continue
				}

				fallbackURL := fmt.Sprintf("https://github.com/ggml-org/llama.cpp/releases/download/%s/%s", version, fallbackFilename)
				fmt.Printf("   Downloading %s binary from: %s\n", fallback, fallbackURL)

				downloadErr = downloadFile(fallbackURL, zipPath)
				if downloadErr == nil {
					// Success with fallback
					fmt.Printf("‚úÖ Successfully downloaded %s binary as fallback\n", fallback)
					if fallback == "vulkan" && binaryType == "cuda" {
						fmt.Printf("üê∏ Vulkan will still provide GPU acceleration\n")
					}
					actualBinaryType = fallback
					break
				}
				fmt.Printf("   ‚ùå %s binary also not available\n", fallback)
			}
		}

		// If still failed, return error
		if downloadErr != nil {
			return nil, fmt.Errorf("failed to download binary: %v", downloadErr)
		}

		// Extract the zip file
		err = extractZip(zipPath, extractDir)
		if err != nil {
			return nil, fmt.Errorf("failed to extract binary: %v", err)
		}
		os.Remove(zipPath)
	}

	// Find the llama-server executable
	fmt.Printf("üîç Searching for llama-server executable in: %s\n", extractDir)
	serverPath, err := FindLlamaServer(extractDir)
	if err != nil {
		return nil, fmt.Errorf("failed to find llama-server executable: %v", err)
	}
	fmt.Printf("‚úÖ Found llama-server at: %s\n", serverPath)

	// Make it executable on Unix systems
	if system.OS != "windows" {
		err = os.Chmod(serverPath, 0755)
		if err != nil {
			return nil, fmt.Errorf("failed to make binary executable: %v", err)
		}
	}

	binaryInfo := &BinaryInfo{
		Path:    serverPath,
		Version: version,
		Type:    actualBinaryType,
	}

	// Save metadata about the downloaded binary
	err = saveBinaryMetadata(extractDir, binaryInfo)
	if err != nil {
		fmt.Printf("‚ö†Ô∏è  Warning: Failed to save binary metadata: %v\n", err)
		// Don't fail the entire process for metadata saving failure
	} else {
		fmt.Printf("üìù Saved binary metadata: %s type, version %s\n", actualBinaryType, version)
	}

	return binaryInfo, nil
}

// downloadFile downloads a file from URL to local path
func downloadFile(url, filepath string) error {
	resp, err := http.Get(url)
	if err != nil {
		return err
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		return fmt.Errorf("failed to download: %s", resp.Status)
	}

	out, err := os.Create(filepath)
	if err != nil {
		return err
	}
	defer out.Close()

	_, err = io.Copy(out, resp.Body)
	return err
}

// extractZip extracts a zip file to destination directory
func extractZip(src, dest string) error {
	r, err := zip.OpenReader(src)
	if err != nil {
		return err
	}
	defer r.Close()

	os.MkdirAll(dest, 0755)

	for _, f := range r.File {
		rc, err := f.Open()
		if err != nil {
			return err
		}
		defer rc.Close()

		path := filepath.Join(dest, f.Name)
		if f.FileInfo().IsDir() {
			os.MkdirAll(path, f.FileInfo().Mode())
			continue
		}

		os.MkdirAll(filepath.Dir(path), 0755)
		f, err := os.OpenFile(path, os.O_WRONLY|os.O_CREATE|os.O_TRUNC, f.FileInfo().Mode())
		if err != nil {
			return err
		}
		defer f.Close()

		_, err = io.Copy(f, rc)
		if err != nil {
			return err
		}
	}

	return nil
}

// FindLlamaServer finds the llama-server executable in extracted directory
func FindLlamaServer(dir string) (string, error) {
	var serverPath string

	// Priority order for searching llama-server executable
	searchPaths := []string{
		filepath.Join(dir, "build", "bin"), // Most common: build/bin/llama-server
		filepath.Join(dir, "bin"),          // Alternative: bin/llama-server
		filepath.Join(dir),                 // Root: llama-server
	}

	// Define possible executable names based on OS
	var executableNames []string
	if runtime.GOOS == "windows" {
		executableNames = []string{
			"llama-server.exe",
			"server.exe",
			"main.exe", // Some builds use main.exe
		}
	} else {
		executableNames = []string{
			"llama-server",
			"server",
			"main", // Some builds use main
		}
	}

	// Search each path in priority order
	for _, searchPath := range searchPaths {
		for _, execName := range executableNames {
			candidatePath := filepath.Join(searchPath, execName)
			if _, err := os.Stat(candidatePath); err == nil {
				// Found the executable, verify it's actually executable
				if runtime.GOOS != "windows" {
					if info, err := os.Stat(candidatePath); err == nil {
						if info.Mode()&0111 != 0 { // Check if executable bit is set
							return candidatePath, nil
						}
					}
				} else {
					// On Windows, if file exists and has .exe extension, it's executable
					return candidatePath, nil
				}
			}
		}
	}

	// Fallback: Walk the entire directory tree as before (for unusual structures)
	err := filepath.Walk(dir, func(path string, info os.FileInfo, err error) error {
		if err != nil {
			return err
		}

		name := info.Name()
		// Look for any file that might be the server executable
		if strings.Contains(strings.ToLower(name), "llama-server") ||
			strings.Contains(strings.ToLower(name), "server") ||
			(strings.Contains(strings.ToLower(name), "main") && !strings.Contains(strings.ToLower(name), ".")) {

			if runtime.GOOS == "windows" && strings.HasSuffix(name, ".exe") {
				serverPath = path
				return filepath.SkipDir
			} else if runtime.GOOS != "windows" && !strings.Contains(name, ".") {
				// Verify it's executable on Unix systems
				if info.Mode()&0111 != 0 {
					serverPath = path
					return filepath.SkipDir
				}
			}
		}

		return nil
	})

	if err != nil {
		return "", err
	}

	if serverPath == "" {
		return "", fmt.Errorf("llama-server executable not found in extracted files. Searched paths: %v", searchPaths)
	}

	return serverPath, nil
}

// Detection functions for different GPU types
func detectCUDA() bool {
	// Check for nvidia-smi command and try to query devices
	var cmd *exec.Cmd

	if runtime.GOOS == "windows" {
		// Check Windows paths for nvidia-smi
		paths := []string{
			"C:\\Program Files\\NVIDIA Corporation\\NVSMI\\nvidia-smi.exe",
			"C:\\Windows\\System32\\nvidia-smi.exe",
		}
		for _, path := range paths {
			if _, err := os.Stat(path); err == nil {
				// Found nvidia-smi, try to query for devices
				cmd = exec.Command(path, "--list-gpus")
				output, err := cmd.Output()
				if err == nil && len(output) > 0 {
					// Check if output contains actual GPU info
					return strings.Contains(string(output), "GPU")
				}
				// nvidia-smi exists but no devices found
				return false
			}
		}
	} else {
		// Check for nvidia-smi on Unix systems
		if _, err := os.Stat("/usr/bin/nvidia-smi"); err == nil {
			cmd = exec.Command("nvidia-smi", "--list-gpus")
			output, err := cmd.Output()
			if err == nil && len(output) > 0 {
				return strings.Contains(string(output), "GPU")
			}
			return false
		}
	}

	return false
}

func detectROCm() bool {
	switch runtime.GOOS {
	case "windows":
		// Check Windows ROCm installation paths
		paths := []string{
			"C:\\Program Files\\AMD\\ROCm\\5.7\\bin\\rocm-smi.exe",
			"C:\\Program Files\\AMD\\ROCm\\5.6\\bin\\rocm-smi.exe",
			"C:\\Program Files\\AMD\\ROCm\\5.5\\bin\\rocm-smi.exe",
			"C:\\AMD\\ROCm\\bin\\rocm-smi.exe",
		}
		for _, path := range paths {
			if _, err := os.Stat(path); err == nil {
				// Found rocm-smi, try to query for devices
				cmd := exec.Command(path, "--showid")
				output, err := cmd.Output()
				if err == nil && len(output) > 0 {
					return strings.Contains(string(output), "GPU")
				}
				return false
			}
		}

		// Check for AMD GPU with ROCm driver
		cmd := exec.Command("wmic", "path", "win32_VideoController", "get", "name")
		output, err := cmd.Output()
		if err == nil && strings.Contains(strings.ToLower(string(output)), "amd") {
			// Check for ROCm runtime
			if _, err := os.Stat("C:\\Windows\\System32\\amdhip64.dll"); err == nil {
				return true
			}
		}

	case "linux":
		// Check for ROCm installation on Linux
		paths := []string{
			"/opt/rocm/bin/rocm-smi",
			"/usr/bin/rocm-smi",
			"/opt/rocm",
		}

		for _, path := range paths {
			if _, err := os.Stat(path); err == nil {
				// Try to query ROCm devices
				if strings.HasSuffix(path, "rocm-smi") {
					cmd := exec.Command(path, "--showid")
					output, err := cmd.Output()
					if err == nil && len(output) > 0 {
						return strings.Contains(string(output), "GPU")
					}
				}
				return true
			}
		}

		// Check for AMD GPU with ROCm driver
		cmd := exec.Command("lspci", "-nn")
		output, err := cmd.Output()
		if err == nil {
			outputStr := strings.ToLower(string(output))
			if strings.Contains(outputStr, "amd") && strings.Contains(outputStr, "display") {
				// Check for ROCm runtime
				if _, err := os.Stat("/usr/lib/x86_64-linux-gnu/libamdhip64.so"); err == nil {
					return true
				}
			}
		}

	case "darwin":
		// ROCm not supported on macOS
		return false
	}

	return false
}

func detectVulkan() bool {
	switch runtime.GOOS {
	case "windows":
		// Check for vulkan-1.dll in system32
		if _, err := os.Stat("C:\\Windows\\System32\\vulkan-1.dll"); err == nil {
			// Try to verify Vulkan devices exist
			cmd := exec.Command("vulkaninfo", "--summary")
			output, err := cmd.Output()
			if err == nil && strings.Contains(string(output), "deviceType") {
				return true
			}
			// Vulkan library exists even if vulkaninfo fails
			return true
		}

	case "linux":
		// Check for libvulkan.so on Linux
		vulkanPaths := []string{
			"/usr/lib/x86_64-linux-gnu/libvulkan.so.1",
			"/usr/lib/libvulkan.so.1",
			"/usr/lib64/libvulkan.so.1",
			"/usr/local/lib/libvulkan.so.1",
			"/lib/x86_64-linux-gnu/libvulkan.so.1",
		}

		for _, path := range vulkanPaths {
			if _, err := os.Stat(path); err == nil {
				// Try to verify Vulkan devices exist
				cmd := exec.Command("vulkaninfo", "--summary")
				output, err := cmd.Output()
				if err == nil && strings.Contains(string(output), "deviceType") {
					return true
				}
				// Vulkan library exists even if vulkaninfo fails
				return true
			}
		}

		// Check for Vulkan using ldconfig
		cmd := exec.Command("ldconfig", "-p")
		output, err := cmd.Output()
		if err == nil && strings.Contains(string(output), "libvulkan.so") {
			return true
		}

	case "darwin":
		// Check for MoltenVK on macOS (Vulkan ‚Üí Metal translation layer)
		moltenVKPaths := []string{
			"/usr/local/lib/libvulkan.1.dylib",
			"/opt/homebrew/lib/libvulkan.1.dylib",
			"/System/Library/Frameworks/Vulkan.framework",
			"/Library/Frameworks/vulkan.framework",
		}

		for _, path := range moltenVKPaths {
			if _, err := os.Stat(path); err == nil {
				return true
			}
		}

		// Check if MoltenVK is installed via Homebrew
		cmd := exec.Command("brew", "list", "molten-vk")
		if err := cmd.Run(); err == nil {
			return true
		}
	}

	return false
}

func detectMetal() bool {
	// Metal is only available on macOS
	if runtime.GOOS != "darwin" {
		return false
	}

	// Check if Metal framework exists
	metalFrameworkPaths := []string{
		"/System/Library/Frameworks/Metal.framework",
		"/System/Library/PrivateFrameworks/Metal.framework",
	}

	for _, path := range metalFrameworkPaths {
		if _, err := os.Stat(path); err == nil {
			// Metal framework exists, verify GPU support
			cmd := exec.Command("system_profiler", "SPDisplaysDataType")
			output, err := cmd.Output()
			if err == nil {
				outputStr := strings.ToLower(string(output))
				// Check for Apple Silicon or modern Intel GPUs with Metal support
				if strings.Contains(outputStr, "apple") ||
					strings.Contains(outputStr, "metal") ||
					strings.Contains(outputStr, "intel iris") ||
					strings.Contains(outputStr, "amd radeon") {
					return true
				}
			}
			// Framework exists, assume Metal support
			return true
		}
	}

	// For Apple Silicon, Metal is always available
	if runtime.GOARCH == "arm64" {
		return true
	}

	return false
}

// Enhanced system detection functions

// EnhanceSystemInfo adds detailed system information to existing SystemInfo
func EnhanceSystemInfo(info *SystemInfo) error {
	// Add CPU information
	info.CPUCores = runtime.NumCPU()
	info.PhysicalCores = detectPhysicalCores()

	// Add RAM information
	info.TotalRAMGB = detectTotalRAM()

	// Enhanced GPU detection
	enhanceGPUDetection(info)

	return nil
}

// detectPhysicalCores detects the number of physical CPU cores
func detectPhysicalCores() int {
	switch runtime.GOOS {
	case "windows":
		return detectWindowsPhysicalCores()
	case "linux":
		return detectLinuxPhysicalCores()
	case "darwin":
		return detectMacOSPhysicalCores()
	default:
		return runtime.NumCPU() / 2 // Fallback assumption
	}
}

// detectWindowsPhysicalCores detects physical cores on Windows
func detectWindowsPhysicalCores() int {
	cmd := exec.Command("wmic", "cpu", "get", "NumberOfCores", "/value")
	output, err := cmd.Output()
	if err != nil {
		return runtime.NumCPU() / 2
	}

	lines := strings.Split(string(output), "\n")
	for _, line := range lines {
		if strings.HasPrefix(line, "NumberOfCores=") {
			coreStr := strings.TrimPrefix(line, "NumberOfCores=")
			coreStr = strings.TrimSpace(coreStr)
			if cores, err := strconv.Atoi(coreStr); err == nil {
				return cores
			}
		}
	}
	return runtime.NumCPU() / 2
}

// detectLinuxPhysicalCores detects physical cores on Linux
func detectLinuxPhysicalCores() int {
	file, err := os.Open("/proc/cpuinfo")
	if err != nil {
		return runtime.NumCPU() / 2
	}
	defer file.Close()

	physicalIDs := make(map[string]bool)
	coresPerSocket := 0

	scanner := bufio.NewScanner(file)
	for scanner.Scan() {
		line := scanner.Text()
		if strings.HasPrefix(line, "physical id") {
			parts := strings.Split(line, ":")
			if len(parts) > 1 {
				physicalIDs[strings.TrimSpace(parts[1])] = true
			}
		} else if strings.HasPrefix(line, "cpu cores") {
			parts := strings.Split(line, ":")
			if len(parts) > 1 {
				if cores, err := strconv.Atoi(strings.TrimSpace(parts[1])); err == nil {
					coresPerSocket = cores
				}
			}
		}
	}

	if len(physicalIDs) > 0 && coresPerSocket > 0 {
		return len(physicalIDs) * coresPerSocket
	}
	return runtime.NumCPU() / 2
}

// detectMacOSPhysicalCores detects physical cores on macOS
func detectMacOSPhysicalCores() int {
	cmd := exec.Command("sysctl", "-n", "hw.physicalcpu")
	output, err := cmd.Output()
	if err != nil {
		return runtime.NumCPU() / 2
	}

	coreStr := strings.TrimSpace(string(output))
	if cores, err := strconv.Atoi(coreStr); err == nil {
		return cores
	}
	return runtime.NumCPU() / 2
}

// detectTotalRAM detects total system RAM in GB
func detectTotalRAM() float64 {
	switch runtime.GOOS {
	case "windows":
		return detectWindowsRAM()
	case "linux":
		return detectLinuxRAM()
	case "darwin":
		return detectMacOSRAM()
	default:
		return 16.0 // Fallback
	}
}

// detectWindowsRAM detects RAM on Windows using modern PowerShell commands
func detectWindowsRAM() float64 {
	// Use PowerShell to get total physical memory capacity
	cmd := exec.Command("powershell", "-Command",
		"Get-CimInstance -ClassName Win32_PhysicalMemory | Measure-Object -Property Capacity -Sum | Select-Object -ExpandProperty Sum")
	output, err := cmd.Output()
	if err != nil {
		return 16.0
	}

	totalBytes, err := strconv.ParseFloat(strings.TrimSpace(string(output)), 64)
	if err != nil {
		return 16.0
	}

	return totalBytes / (1024 * 1024 * 1024) // Convert bytes to GB
}

// detectLinuxRAM detects RAM on Linux
func detectLinuxRAM() float64 {
	file, err := os.Open("/proc/meminfo")
	if err != nil {
		return 16.0
	}
	defer file.Close()

	scanner := bufio.NewScanner(file)
	for scanner.Scan() {
		line := scanner.Text()
		if strings.HasPrefix(line, "MemTotal:") {
			fields := strings.Fields(line)
			if len(fields) >= 2 {
				if memKB, err := strconv.ParseInt(fields[1], 10, 64); err == nil {
					return float64(memKB) / (1024 * 1024)
				}
			}
		}
	}
	return 16.0
}

// detectMacOSRAM detects RAM on macOS
func detectMacOSRAM() float64 {
	cmd := exec.Command("sysctl", "-n", "hw.memsize")
	output, err := cmd.Output()
	if err != nil {
		return 16.0
	}

	memStr := strings.TrimSpace(string(output))
	if memBytes, err := strconv.ParseInt(memStr, 10, 64); err == nil {
		return float64(memBytes) / (1024 * 1024 * 1024)
	}
	return 16.0
}

// enhanceGPUDetection adds detailed GPU and VRAM information
func enhanceGPUDetection(info *SystemInfo) {
	// Enhanced CUDA detection
	if info.HasCUDA {
		enhanceCUDADetection(info)
	}

	// Enhanced ROCm detection
	if info.HasROCm {
		enhanceROCmDetection(info)
	}

	// MLX detection for Apple Silicon
	if runtime.GOOS == "darwin" {
		enhanceMLXDetection(info)
	}

	// Intel GPU detection
	enhanceIntelGPUDetection(info)

	// Calculate total VRAM
	for _, gpu := range info.VRAMDetails {
		info.TotalVRAMGB += gpu.VRAMGB
	}
}

// enhanceCUDADetection gets detailed NVIDIA GPU information
func enhanceCUDADetection(info *SystemInfo) {
	// Try nvidia-smi for detailed info
	cmd := exec.Command("nvidia-smi", "--query-gpu=name,memory.total", "--format=csv,noheader,nounits")
	output, err := cmd.Output()
	if err != nil {
		return
	}

	// Get CUDA version
	versionCmd := exec.Command("nvcc", "--version")
	if versionOutput, err := versionCmd.Output(); err == nil {
		lines := strings.Split(string(versionOutput), "\n")
		for _, line := range lines {
			if strings.Contains(line, "release") {
				parts := strings.Fields(line)
				for i, part := range parts {
					if part == "release" && i+1 < len(parts) {
						info.CUDAVersion = strings.TrimSuffix(parts[i+1], ",")
						break
					}
				}
			}
		}
	}

	// Parse GPU info
	lines := strings.Split(string(output), "\n")
	for i, line := range lines {
		line = strings.TrimSpace(line)
		if line == "" {
			continue
		}

		parts := strings.Split(line, ", ")
		if len(parts) >= 2 {
			name := strings.TrimSpace(parts[0])
			vramStr := strings.TrimSpace(parts[1])

			if vramMB, err := strconv.ParseFloat(vramStr, 64); err == nil {
				info.VRAMDetails = append(info.VRAMDetails, GPUInfo{
					Name:     name,
					VRAMGB:   vramMB / 1024.0,
					Type:     "CUDA",
					DeviceID: i,
				})
			}
		}
	}
}

// enhanceROCmDetection gets detailed AMD GPU information
func enhanceROCmDetection(info *SystemInfo) {
	// Try rocm-smi
	cmd := exec.Command("rocm-smi", "--showproductname", "--showmeminfo", "vram")
	output, err := cmd.Output()
	if err != nil {
		// Fallback: assume basic AMD GPU
		info.VRAMDetails = append(info.VRAMDetails, GPUInfo{
			Name:     "AMD GPU",
			VRAMGB:   8.0, // Conservative estimate
			Type:     "ROCm",
			DeviceID: 0,
		})
		return
	}

	// Parse ROCm GPU info (simplified)
	lines := strings.Split(string(output), "\n")
	deviceID := 0
	for _, line := range lines {
		if strings.Contains(line, "GPU") && strings.Contains(line, "MB") {
			// Basic parsing - would need more sophisticated parsing
			info.VRAMDetails = append(info.VRAMDetails, GPUInfo{
				Name:     "AMD GPU",
				VRAMGB:   8.0, // Placeholder
				Type:     "ROCm",
				DeviceID: deviceID,
			})
			deviceID++
		}
	}
}

// enhanceMLXDetection detects Apple Metal/MLX capabilities
func enhanceMLXDetection(info *SystemInfo) {
	// MLX is only for Apple Silicon Macs
	if runtime.GOARCH != "arm64" {
		return
	}

	// Check for Metal Performance Shaders framework
	metalFrameworks := []string{
		"/System/Library/Frameworks/Metal.framework",
		"/System/Library/Frameworks/MetalPerformanceShaders.framework",
	}

	hasMetalFramework := false
	for _, framework := range metalFrameworks {
		if _, err := os.Stat(framework); err == nil {
			hasMetalFramework = true
			break
		}
	}

	if !hasMetalFramework {
		return
	}

	// Get detailed system info for Apple Silicon
	cmd := exec.Command("system_profiler", "SPHardwareDataType", "SPDisplaysDataType")
	output, err := cmd.Output()
	if err != nil {
		// Fallback for Apple Silicon
		info.HasMLX = true
		info.VRAMDetails = append(info.VRAMDetails, GPUInfo{
			Name:     "Apple GPU",
			VRAMGB:   getAppleSiliconUnifiedMemory(),
			Type:     "MLX",
			DeviceID: 0,
		})
		return
	}

	outputStr := strings.ToLower(string(output))

	// Detect Apple Silicon chip type for memory estimates
	var gpuName string
	var unifiedMemoryGB float64

	// Look for chip name patterns in the output - be more flexible with matching
	if strings.Contains(outputStr, "m1") || strings.Contains(outputStr, "apple m1") {
		if strings.Contains(outputStr, "max") {
			gpuName = "Apple M1 Max"
			unifiedMemoryGB = 32.0 // M1 Max typical config
		} else if strings.Contains(outputStr, "pro") {
			gpuName = "Apple M1 Pro"
			unifiedMemoryGB = 16.0 // M1 Pro typical config
		} else {
			gpuName = "Apple M1"
			unifiedMemoryGB = 8.0 // Base M1 typical config
		}
	} else if strings.Contains(outputStr, "m2") || strings.Contains(outputStr, "apple m2") {
		if strings.Contains(outputStr, "ultra") {
			gpuName = "Apple M2 Ultra"
			unifiedMemoryGB = 96.0 // M2 Ultra high-end config
		} else if strings.Contains(outputStr, "max") {
			gpuName = "Apple M2 Max"
			unifiedMemoryGB = 38.0 // M2 Max typical config
		} else if strings.Contains(outputStr, "pro") {
			gpuName = "Apple M2 Pro"
			unifiedMemoryGB = 16.0 // M2 Pro typical config
		} else {
			gpuName = "Apple M2"
			unifiedMemoryGB = 8.0 // Base M2 typical config
		}
	} else if strings.Contains(outputStr, "m3") || strings.Contains(outputStr, "apple m3") {
		if strings.Contains(outputStr, "max") {
			gpuName = "Apple M3 Max"
			unifiedMemoryGB = 48.0 // M3 Max typical config
		} else if strings.Contains(outputStr, "pro") {
			gpuName = "Apple M3 Pro"
			unifiedMemoryGB = 18.0 // M3 Pro typical config
		} else {
			gpuName = "Apple M3"
			unifiedMemoryGB = 8.0 // Base M3 typical config
		}
	} else if strings.Contains(outputStr, "m4") || strings.Contains(outputStr, "apple m4") {
		if strings.Contains(outputStr, "max") {
			gpuName = "Apple M4 Max"
			unifiedMemoryGB = 64.0 // M4 Max estimated config
		} else if strings.Contains(outputStr, "pro") {
			gpuName = "Apple M4 Pro"
			unifiedMemoryGB = 24.0 // M4 Pro estimated config
		} else {
			gpuName = "Apple M4"
			unifiedMemoryGB = 10.0 // Base M4 estimated config
		}
	} else if runtime.GOARCH == "arm64" {
		// Running on Apple Silicon but couldn't detect specific chip
		gpuName = "Apple Silicon GPU"
		unifiedMemoryGB = getAppleSiliconUnifiedMemory()
	} else {
		// Intel Mac or unknown - use conservative estimate
		gpuName = "Apple GPU"
		unifiedMemoryGB = getAppleSiliconUnifiedMemory()
	}

	// Check for actual total memory and adjust
	if info.TotalRAMGB > 0 {
		// Use 70% of total RAM as available for GPU tasks (conservative)
		adjustedMemory := info.TotalRAMGB * 0.7
		if adjustedMemory < unifiedMemoryGB {
			unifiedMemoryGB = adjustedMemory
		}
	}

	info.HasMLX = true
	info.VRAMDetails = append(info.VRAMDetails, GPUInfo{
		Name:     gpuName,
		VRAMGB:   unifiedMemoryGB,
		Type:     "MLX",
		DeviceID: 0,
	})
}

// getAppleSiliconUnifiedMemory estimates unified memory for Apple Silicon
func getAppleSiliconUnifiedMemory() float64 {
	// Get total system memory and estimate GPU portion
	cmd := exec.Command("sysctl", "-n", "hw.memsize")
	output, err := cmd.Output()
	if err != nil {
		return 8.0 // Conservative fallback
	}

	memStr := strings.TrimSpace(string(output))
	if memBytes, err := strconv.ParseInt(memStr, 10, 64); err == nil {
		totalGB := float64(memBytes) / (1024 * 1024 * 1024)
		// Use 70% of total memory as available for GPU tasks
		return totalGB * 0.7
	}
	return 8.0 // Fallback
}

// PrintPlatformSupportSummary prints a comprehensive summary of platform support
func PrintPlatformSupportSummary() {
	fmt.Printf("\nüåç FrogLLM Platform Support Matrix:\n")
	fmt.Printf("‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n")

	// Windows Support
	fmt.Printf("ü™ü WINDOWS SUPPORT:\n")
	fmt.Printf("   ‚úÖ NVIDIA CUDA    - Best performance (RTX 40/30/20 series, GTX)\n")
	fmt.Printf("   ‚úÖ AMD ROCm       - AMD GPU acceleration (RX 7000/6000/5000 series)\n")
	fmt.Printf("   ‚úÖ Vulkan        - Cross-platform GPU support\n")
	fmt.Printf("   ‚úÖ Intel GPU     - Integrated graphics acceleration\n")
	fmt.Printf("   ‚úÖ CPU           - Multithreaded fallback\n")
	fmt.Printf("   üéØ Priority: CUDA > ROCm > Vulkan > CPU\n\n")

	// Linux Support
	fmt.Printf("üêß LINUX SUPPORT:\n")
	fmt.Printf("   ‚úÖ NVIDIA CUDA    - Optimal for data centers & gaming rigs\n")
	fmt.Printf("   ‚úÖ AMD ROCm       - Open-source AMD GPU acceleration\n")
	fmt.Printf("   ‚úÖ Vulkan        - Modern GPU API support\n")
	fmt.Printf("   ‚úÖ Intel GPU     - Integrated & discrete Intel graphics\n")
	fmt.Printf("   ‚úÖ CPU           - Excellent Linux optimization\n")
	fmt.Printf("   üéØ Priority: CUDA > ROCm > Vulkan > CPU\n\n")

	// macOS Support
	fmt.Printf("üçé macOS SUPPORT:\n")
	fmt.Printf("   ‚úÖ Apple MLX      - Apple Silicon unified memory (M1/M2/M3/M4)\n")
	fmt.Printf("   ‚úÖ Metal         - Apple GPU acceleration framework\n")
	fmt.Printf("   ‚úÖ Vulkan (MoltenVK) - Cross-platform compatibility layer\n")
	fmt.Printf("   ‚úÖ Intel GPU     - Intel Mac integrated graphics\n")
	fmt.Printf("   ‚úÖ CPU           - macOS-optimized processing\n")
	fmt.Printf("   üéØ Priority: Metal+MLX > Vulkan > CPU\n\n")

	// Hardware Recommendations
	fmt.Printf("üîß HARDWARE RECOMMENDATIONS:\n")
	fmt.Printf("   ü•á Best:    NVIDIA RTX 4090 (24GB) / RTX 4080 (16GB) - Windows/Linux\n")
	fmt.Printf("   ü•á Best:    Apple M3 Max (128GB) / M2 Ultra (192GB) - macOS\n")
	fmt.Printf("   ü•à Great:   AMD RX 7900XTX (24GB) / RTX 3080 Ti (12GB)\n")
	fmt.Printf("   ü•â Good:    RTX 3060 (12GB) / Intel Arc A770 (16GB)\n")
	fmt.Printf("   üíª Budget:  CPU-only with 32GB+ RAM\n\n")

	// Model Size Recommendations
	fmt.Printf("üìä MODEL SIZE vs HARDWARE:\n")
	fmt.Printf("   ü§ñ 70B+ models:  24GB+ VRAM or Apple Silicon with 64GB+ unified memory\n")
	fmt.Printf("   ü§ñ 30B models:   16GB+ VRAM or 32GB+ unified memory\n")
	fmt.Printf("   ü§ñ 13B models:   8GB+ VRAM or 16GB+ unified memory\n")
	fmt.Printf("   ü§ñ 7B models:    6GB+ VRAM or 8GB+ unified memory\n")
	fmt.Printf("   ü§ñ 3B models:    4GB+ VRAM or 4GB+ unified memory\n\n")

	// Installation Notes
	fmt.Printf("üìù INSTALLATION NOTES:\n")
	fmt.Printf("   Windows: Automatic driver detection and binary selection\n")
	fmt.Printf("   Linux:   Install CUDA/ROCm drivers manually for best performance\n")
	fmt.Printf("   macOS:   Metal/MLX work out-of-the-box on Apple Silicon\n")
	fmt.Printf("‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n")
}

// enhanceIntelGPUDetection detects Intel integrated GPUs
func enhanceIntelGPUDetection(info *SystemInfo) {
	switch runtime.GOOS {
	case "windows":
		cmd := exec.Command("wmic", "path", "win32_VideoController", "get", "name,AdapterRAM")
		output, err := cmd.Output()
		if err != nil {
			return
		}

		outputStr := strings.ToLower(string(output))
		if strings.Contains(outputStr, "intel") {
			// Parse Intel GPU details
			lines := strings.Split(string(output), "\n")
			var gpuName string
			var sharedMemoryGB float64 = 4.0 // Default estimate

			for _, line := range lines {
				if strings.Contains(strings.ToLower(line), "intel") && !strings.Contains(line, "AdapterRAM") {
					parts := strings.Fields(line)
					if len(parts) > 0 {
						// Extract GPU name and memory estimate
						if strings.Contains(strings.ToLower(line), "iris xe") {
							gpuName = "Intel Iris Xe"
							sharedMemoryGB = 8.0 // Modern integrated GPU
						} else if strings.Contains(strings.ToLower(line), "iris") {
							gpuName = "Intel Iris"
							sharedMemoryGB = 6.0
						} else {
							gpuName = "Intel HD Graphics"
							sharedMemoryGB = 4.0
						}
						break
					}
				}
			}

			info.HasIntel = true
			info.VRAMDetails = append(info.VRAMDetails, GPUInfo{
				Name:     gpuName,
				VRAMGB:   sharedMemoryGB,
				Type:     "Intel",
				DeviceID: 0,
			})
		}

	case "linux":
		// Check for Intel GPU on Linux
		cmd := exec.Command("lspci", "-v")
		output, err := cmd.Output()
		if err != nil {
			return
		}

		outputStr := strings.ToLower(string(output))
		if strings.Contains(outputStr, "intel") && strings.Contains(outputStr, "graphics") {
			var gpuName string
			var sharedMemoryGB float64 = 4.0

			// Parse for specific Intel GPU types
			if strings.Contains(outputStr, "iris xe") {
				gpuName = "Intel Iris Xe"
				sharedMemoryGB = 8.0
			} else if strings.Contains(outputStr, "iris") {
				gpuName = "Intel Iris"
				sharedMemoryGB = 6.0
			} else if strings.Contains(outputStr, "uhd") {
				gpuName = "Intel UHD Graphics"
				sharedMemoryGB = 5.0
			} else {
				gpuName = "Intel HD Graphics"
				sharedMemoryGB = 4.0
			}

			info.HasIntel = true
			info.VRAMDetails = append(info.VRAMDetails, GPUInfo{
				Name:     gpuName,
				VRAMGB:   sharedMemoryGB,
				Type:     "Intel",
				DeviceID: 0,
			})
		}

	case "darwin":
		// Check for Intel GPU on Intel-based Macs
		if runtime.GOARCH == "amd64" { // Intel Macs
			cmd := exec.Command("system_profiler", "SPDisplaysDataType")
			output, err := cmd.Output()
			if err != nil {
				return
			}

			outputStr := strings.ToLower(string(output))
			if strings.Contains(outputStr, "intel") {
				var gpuName string
				var sharedMemoryGB float64 = 1.5 // macOS Intel integrated

				if strings.Contains(outputStr, "iris") {
					gpuName = "Intel Iris Pro"
					sharedMemoryGB = 2.0
				} else {
					gpuName = "Intel HD Graphics"
					sharedMemoryGB = 1.5
				}

				info.HasIntel = true
				info.VRAMDetails = append(info.VRAMDetails, GPUInfo{
					Name:     gpuName,
					VRAMGB:   sharedMemoryGB,
					Type:     "Intel",
					DeviceID: 0,
				})
			}
		}
	}
}

// ModelFileInfo contains detailed information about a model file
type ModelFileInfo struct {
	Path           string
	ActualSizeGB   float64
	LayerCount     int
	ContextLength  int
	Architecture   string
	ParameterCount string
	Quantization   string
	SlidingWindow  uint32
}

// GetModelFileInfo reads detailed information from a GGUF model file
func GetModelFileInfo(modelPath string) (*ModelFileInfo, error) {
	// Get file size
	fileInfo, err := os.Stat(modelPath)
	if err != nil {
		return nil, fmt.Errorf("failed to get file info: %w", err)
	}

	actualSize := float64(fileInfo.Size()) / (1024 * 1024 * 1024) // Convert to GB

	// Handle multi-part models
	if strings.Contains(filepath.Base(modelPath), "-of-") {
		actualSize = getTotalMultiPartSize(modelPath)
	}

	// Read GGUF metadata
	metadata, err := ReadGGUFMetadata(modelPath)
	if err != nil {
		return &ModelFileInfo{
			Path:          modelPath,
			ActualSizeGB:  actualSize,
			LayerCount:    0,
			Quantization:  detectQuantizationFromFilename(modelPath),
			SlidingWindow: 0,
		}, nil // Return partial info even if GGUF reading fails
	}

	return &ModelFileInfo{
		Path:           modelPath,
		ActualSizeGB:   actualSize,
		LayerCount:     int(metadata.BlockCount),
		ContextLength:  int(metadata.ContextLength),
		Architecture:   metadata.Architecture,
		ParameterCount: metadata.ModelName,
		Quantization:   detectQuantizationFromFilename(modelPath),
		SlidingWindow:  metadata.SlidingWindow,
	}, nil
}

// getTotalMultiPartSize calculates total size of multi-part models
func getTotalMultiPartSize(modelPath string) float64 {
	dir := filepath.Dir(modelPath)
	base := filepath.Base(modelPath)

	// Extract pattern like "model-00001-of-00003.gguf"
	parts := strings.Split(base, "-")
	if len(parts) < 3 {
		return 0
	}

	var totalSize int64
	files, err := os.ReadDir(dir)
	if err != nil {
		return 0
	}

	for _, file := range files {
		if strings.Contains(file.Name(), "-of-") && strings.HasSuffix(file.Name(), ".gguf") {
			if info, err := file.Info(); err == nil {
				totalSize += info.Size()
			}
		}
	}

	return float64(totalSize) / (1024 * 1024 * 1024)
}

// detectQuantizationFromFilename detects quantization type from filename
func detectQuantizationFromFilename(filename string) string {
	filename = strings.ToUpper(filename)

	quantTypes := []string{"Q4_K_M", "Q4_K_S", "Q5_K_M", "Q5_K_S", "Q8_0", "Q6_K", "IQ4_XS", "F16", "F32"}

	for _, qtype := range quantTypes {
		if strings.Contains(filename, qtype) {
			return qtype
		}
	}

	return "Unknown"
}

// PrintSystemInfo prints comprehensive system information with platform-specific details
func PrintSystemInfo(info *SystemInfo) {
	fmt.Printf("üñ•Ô∏è  System Information:\n")
	fmt.Printf("   OS: %s/%s\n", info.OS, info.Architecture)
	fmt.Printf("   CPU Cores: %d logical, %d physical\n", info.CPUCores, info.PhysicalCores)
	fmt.Printf("   Total RAM: %.1f GB\n", info.TotalRAMGB)

	// Platform-specific acceleration support
	fmt.Printf("üöÄ Platform Acceleration Support:\n")

	switch info.OS {
	case "windows":
		fmt.Printf("   ü™ü Windows Platform:\n")
		if info.HasCUDA {
			fmt.Printf("      ‚úÖ NVIDIA CUDA")
			if info.CUDAVersion != "" {
				fmt.Printf(" (v%s)", info.CUDAVersion)
			}
			fmt.Printf(" - Best performance for NVIDIA GPUs\n")
		}
		if info.HasROCm {
			fmt.Printf("      ‚úÖ AMD ROCm")
			if info.ROCmVersion != "" {
				fmt.Printf(" (v%s)", info.ROCmVersion)
			}
			fmt.Printf(" - AMD GPU acceleration\n")
		}
		if info.HasVulkan {
			fmt.Printf("      ‚úÖ Vulkan - Cross-platform GPU acceleration\n")
		}
		if info.HasIntel {
			fmt.Printf("      ‚úÖ Intel GPU - Integrated graphics acceleration\n")
		}
		if !info.HasCUDA && !info.HasROCm && !info.HasVulkan && !info.HasIntel {
			fmt.Printf("      üíª CPU-only - Software acceleration\n")
		}

	case "linux":
		fmt.Printf("   üêß Linux Platform:\n")
		if info.HasCUDA {
			fmt.Printf("      ‚úÖ NVIDIA CUDA")
			if info.CUDAVersion != "" {
				fmt.Printf(" (v%s)", info.CUDAVersion)
			}
			fmt.Printf(" - Optimal for NVIDIA GPUs\n")
		}
		if info.HasROCm {
			fmt.Printf("      ‚úÖ AMD ROCm")
			if info.ROCmVersion != "" {
				fmt.Printf(" (v%s)", info.ROCmVersion)
			}
			fmt.Printf(" - AMD GPU acceleration\n")
		}
		if info.HasVulkan {
			fmt.Printf("      ‚úÖ Vulkan - Universal GPU acceleration\n")
		}
		if info.HasIntel {
			fmt.Printf("      ‚úÖ Intel GPU - Integrated graphics support\n")
		}
		if !info.HasCUDA && !info.HasROCm && !info.HasVulkan && !info.HasIntel {
			fmt.Printf("      üíª CPU-only - Multithreaded processing\n")
		}

	case "darwin":
		fmt.Printf("   üçé macOS Platform:\n")
		if info.HasMLX && runtime.GOARCH == "arm64" {
			fmt.Printf("      ‚úÖ Apple MLX - Optimized for Apple Silicon\n")
		}
		if info.HasMetal {
			fmt.Printf("      ‚úÖ Metal - Apple GPU acceleration\n")
		}
		if info.HasVulkan {
			fmt.Printf("      ‚úÖ Vulkan (MoltenVK) - Cross-platform compatibility\n")
		}
		if info.HasIntel && runtime.GOARCH == "amd64" {
			fmt.Printf("      ‚úÖ Intel GPU - Intel Mac graphics\n")
		}
		if runtime.GOARCH == "amd64" && !info.HasMetal && !info.HasVulkan && !info.HasIntel {
			fmt.Printf("      üíª CPU-only - Intel Mac software processing\n")
		}
	}

	// GPU Memory Details
	if len(info.VRAMDetails) > 0 {
		fmt.Printf("\nüíæ GPU Memory Information:\n")
		fmt.Printf("   Total Available: %.1f GB\n", info.TotalVRAMGB)
		for i, gpu := range info.VRAMDetails {
			emoji := getGPUEmoji(gpu.Type)
			fmt.Printf("   %s GPU %d: %s (%.1f GB)\n", emoji, i, gpu.Name, gpu.VRAMGB)

			// Add platform-specific notes
			switch gpu.Type {
			case "CUDA":
				fmt.Printf("      üéØ Optimal for large language models\n")
			case "ROCm":
				fmt.Printf("      üî• AMD GPU acceleration with ROCm\n")
			case "MLX":
				fmt.Printf("      üß† Unified memory for Apple Silicon efficiency\n")
			case "Intel":
				fmt.Printf("      ‚ö° Shared system memory for GPU tasks\n")
			}
		}
	} else {
		fmt.Printf("\nüíª No dedicated GPU memory - Using system RAM\n")
	}

	// Platform recommendations
	fmt.Printf("\nüí° Platform Recommendations:\n")
	switch info.OS {
	case "windows":
		if info.HasCUDA {
			fmt.Printf("   ü•á CUDA backend recommended for best performance\n")
		} else if info.HasROCm {
			fmt.Printf("   ü•à ROCm backend recommended for AMD GPUs\n")
		} else if info.HasVulkan {
			fmt.Printf("   ü•â Vulkan backend for cross-platform compatibility\n")
		} else {
			fmt.Printf("   üíª CPU backend - Consider GPU upgrade for better performance\n")
		}
	case "linux":
		if info.HasCUDA {
			fmt.Printf("   ü•á CUDA backend optimal for NVIDIA hardware\n")
		} else if info.HasROCm {
			fmt.Printf("   ü•à ROCm backend excellent for AMD GPUs\n")
		} else if info.HasVulkan {
			fmt.Printf("   ü•â Vulkan backend for modern GPU support\n")
		} else {
			fmt.Printf("   üíª CPU backend with excellent Linux optimization\n")
		}
	case "darwin":
		if info.HasMLX && runtime.GOARCH == "arm64" {
			fmt.Printf("   ü•á Metal backend optimal for Apple Silicon\n")
			fmt.Printf("   ‚ö° MLX framework provides best efficiency\n")
		} else if info.HasMetal {
			fmt.Printf("   ü•à Metal backend for GPU acceleration\n")
		} else if info.HasVulkan {
			fmt.Printf("   ü•â Vulkan (MoltenVK) for compatibility\n")
		} else {
			fmt.Printf("   üíª CPU backend with macOS optimizations\n")
		}
	}
}

// getGPUEmoji returns appropriate emoji for GPU type
func getGPUEmoji(gpuType string) string {
	switch gpuType {
	case "CUDA":
		return "üü¢" // NVIDIA green
	case "ROCm":
		return "üî¥" // AMD red
	case "MLX":
		return "üçé" // Apple
	case "Intel":
		return "üîµ" // Intel blue
	default:
		return "‚ö™" // Generic
	}
}

// PrintModelInfo prints detailed model information
func PrintModelInfo(models []ModelInfo, modelsPath string) {
	fmt.Printf("üìÅ Model Analysis:\n")

	var totalSizeGB float64
	validModels := 0

	for _, model := range models {
		if model.IsDraft {
			continue
		}

		modelInfo, err := GetModelFileInfo(model.Path)
		if err != nil {
			fmt.Printf("   ‚ö†Ô∏è  %s: Failed to read file info\n", model.Name)
			continue
		}

		totalSizeGB += modelInfo.ActualSizeGB
		validModels++

		fmt.Printf("   üì¶ %s:\n", model.Name)
		fmt.Printf("      Size: %.2f GB\n", modelInfo.ActualSizeGB)
		if modelInfo.LayerCount > 0 {
			fmt.Printf("      Layers: %d\n", modelInfo.LayerCount)
		}
		if modelInfo.ContextLength > 0 {
			fmt.Printf("      Max Context: %d tokens\n", modelInfo.ContextLength)
		}
		if modelInfo.Architecture != "" {
			fmt.Printf("      Architecture: %s\n", modelInfo.Architecture)
		}
		if modelInfo.SlidingWindow > 0 {
			fmt.Printf("      SWA Support: Yes (window size: %d)\n", modelInfo.SlidingWindow)
		}
		fmt.Printf("      Quantization: %s\n", modelInfo.Quantization)
	}

	fmt.Printf("   üìä Summary: %d models, %.2f GB total\n", validModels, totalSizeGB)
}

// DebugMMProjMetadata reads and prints all metadata keys from mmproj files
func DebugMMProjMetadata(modelsPath string) {
	fmt.Printf("üîç Scanning for mmproj files in: %s\n", modelsPath)

	// Find all mmproj files
	var mmprojFiles []string

	err := filepath.Walk(modelsPath, func(path string, info os.FileInfo, err error) error {
		if err != nil {
			return nil
		}

		if !info.IsDir() && strings.Contains(strings.ToLower(info.Name()), "mmproj") && strings.HasSuffix(path, ".gguf") {
			mmprojFiles = append(mmprojFiles, path)
		}

		return nil
	})

	if err != nil {
		fmt.Printf("Error scanning directory: %v\n", err)
		return
	}

	fmt.Printf("üì¶ Found %d mmproj files:\n", len(mmprojFiles))

	for i, mmprojPath := range mmprojFiles {
		fmt.Printf("\n--- mmproj file %d: %s ---\n", i+1, filepath.Base(mmprojPath))

		// Try to read GGUF metadata
		allKeys, err := ReadAllGGUFKeys(mmprojPath)
		if err != nil {
			fmt.Printf("‚ùå Failed to read metadata: %v\n", err)
			continue
		}

		fmt.Printf("üìä Total metadata keys found: %d\n", len(allKeys))
		fmt.Printf("üéØ Interesting keys:\n")

		// Print interesting keys for vision models
		interestingPrefixes := []string{
			"clip.",
			"vision.",
			"projector.",
			"original.",
			"general.",
			"model.",
			"llava.",
			"mm.",
		}

		for key, value := range allKeys {
			for _, prefix := range interestingPrefixes {
				if strings.HasPrefix(strings.ToLower(key), prefix) {
					fmt.Printf("   %s: %v\n", key, value)
					break
				}
			}
		}

		fmt.Printf("\nüìù All keys (first 50):\n")
		count := 0
		for key := range allKeys {
			if count >= 50 {
				fmt.Printf("   ... and %d more keys\n", len(allKeys)-50)
				break
			}
			fmt.Printf("   - %s\n", key)
			count++
		}
	}

	if len(mmprojFiles) == 0 {
		fmt.Printf("‚ùå No mmproj files found\n")
	}
}

// DebugModelMetadata reads and prints metadata keys from sample main model files to compare with mmproj
func DebugModelMetadata(models []ModelInfo) {
	fmt.Printf("\nüîç Analyzing main model metadata for matching keys...\n")

	// Pick a few different models to analyze (max 3 for brevity)
	sampledModels := []ModelInfo{}
	for _, model := range models {
		if !model.IsDraft && len(sampledModels) < 3 {
			sampledModels = append(sampledModels, model)
		}
		if len(sampledModels) >= 3 {
			break
		}
	}

	if len(sampledModels) == 0 {
		fmt.Printf("‚ùå No valid models found for analysis\n")
		return
	}

	fmt.Printf("üì¶ Analyzing %d sample models:\n", len(sampledModels))

	for i, model := range sampledModels {
		fmt.Printf("\n--- Model %d: %s ---\n", i+1, model.Name)

		// Try to read GGUF metadata
		allKeys, err := ReadAllGGUFKeys(model.Path)
		if err != nil {
			fmt.Printf("‚ùå Failed to read metadata: %v\n", err)
			continue
		}

		fmt.Printf("üìä Total metadata keys found: %d\n", len(allKeys))
		fmt.Printf("üéØ Keys that might help match with mmproj:\n")

		// Print keys that might be useful for matching with mmproj files
		matchingPrefixes := []string{
			"general.",
			"llama.",
			"model.",
			"tokenizer.",
			"clip.",
			"vision.",
		}

		for key, value := range allKeys {
			for _, prefix := range matchingPrefixes {
				if strings.HasPrefix(strings.ToLower(key), prefix) {
					// Only show keys that might contain model identification info
					if strings.Contains(strings.ToLower(key), "name") ||
						strings.Contains(strings.ToLower(key), "base") ||
						strings.Contains(strings.ToLower(key), "type") ||
						strings.Contains(strings.ToLower(key), "arch") ||
						strings.Contains(strings.ToLower(key), "family") ||
						strings.Contains(strings.ToLower(key), "id") {
						fmt.Printf("   %s: %v\n", key, value)
					}
					break
				}
			}
		}

		fmt.Printf("\nüìù All general.* keys:\n")
		for key, value := range allKeys {
			if strings.HasPrefix(strings.ToLower(key), "general.") {
				fmt.Printf("   %s: %v\n", key, value)
			}
		}
	}
}

// MMProjMatch represents a matched mmproj file with a main model
type MMProjMatch struct {
	ModelPath    string
	ModelName    string
	MMProjPath   string
	MMProjName   string
	MatchType    string  // "architecture", "basename", "name_similarity"
	Confidence   float64 // 0.0 to 1.0
	MatchDetails string
}

// FindMMProjMatches finds and matches mmproj files with their corresponding main models
func FindMMProjMatches(models []ModelInfo, modelsPath string) []MMProjMatch {
	fmt.Printf("üîó Searching for mmproj-to-model matches...\n")

	// Find all mmproj files
	var mmprojFiles []string
	err := filepath.Walk(modelsPath, func(path string, info os.FileInfo, err error) error {
		if err != nil {
			return nil
		}
		if !info.IsDir() && strings.Contains(strings.ToLower(info.Name()), "mmproj") && strings.HasSuffix(path, ".gguf") {
			mmprojFiles = append(mmprojFiles, path)
		}
		return nil
	})

	if err != nil {
		fmt.Printf("‚ùå Error scanning for mmproj files: %v\n", err)
		return []MMProjMatch{}
	}

	var matches []MMProjMatch

	// For each mmproj file, try to find matching models
	for _, mmprojPath := range mmprojFiles {
		fmt.Printf("\nüîç Analyzing mmproj: %s\n", filepath.Base(mmprojPath))

		// Read mmproj metadata
		mmprojMeta, err := ReadAllGGUFKeys(mmprojPath)
		if err != nil {
			fmt.Printf("   ‚ùå Failed to read mmproj metadata: %v\n", err)
			continue
		}

		// Extract key matching fields from mmproj
		mmprojArch := getStringValue(mmprojMeta, "clip.projector_type")
		mmprojName := getStringValue(mmprojMeta, "general.name")
		mmprojBasename := getStringValue(mmprojMeta, "general.basename")
		mmprojBaseModelName := getStringValue(mmprojMeta, "general.base_model.0.name")

		// For mmproj: look for projection dimensions
		mmprojEmbedDim := getIntValue(mmprojMeta, "clip.vision.projection_dim")

		fmt.Printf("   üìã mmproj fields: arch=%s, name=%s, basename=%s, base_model=%s, proj_dim=%d\n",
			mmprojArch, mmprojName, mmprojBasename, mmprojBaseModelName, mmprojEmbedDim)

		// Try to match with each main model
		for _, model := range models {
			if model.IsDraft {
				continue // Skip draft models (including other mmproj files)
			}

			// Read model metadata
			modelMeta, err := ReadAllGGUFKeys(model.Path)
			if err != nil {
				continue
			}

			// Extract key matching fields from model
			modelArch := getStringValue(modelMeta, "general.architecture")
			modelName := getStringValue(modelMeta, "general.name")
			modelBasename := getStringValue(modelMeta, "general.basename")
			modelBaseModelName := getStringValue(modelMeta, "general.base_model.0.name")

			// Try different matching strategies

			// 1. Architecture + name-based size matching (highest confidence)
			if mmprojArch != "" && modelArch != "" &&
				strings.EqualFold(mmprojArch, modelArch) {

				// Check if model size matches mmproj expectations
				nameCompatibility := isModelNameCompatibleWithMMProj(model.Name, mmprojEmbedDim)
				if nameCompatibility {
					matches = append(matches, MMProjMatch{
						ModelPath:    model.Path,
						ModelName:    model.Name,
						MMProjPath:   mmprojPath,
						MMProjName:   filepath.Base(mmprojPath),
						MatchType:    "architecture_name_compatible",
						Confidence:   0.90,
						MatchDetails: fmt.Sprintf("arch: %s ‚Üí %s, name-size match for %d dim", mmprojArch, modelArch, mmprojEmbedDim),
					})
					fmt.Printf("   ‚úÖ ARCH+NAME MATCH: %s (conf: 0.90) [%s arch, size compatible with %d dim]\n",
						model.Name, mmprojArch, mmprojEmbedDim)
					continue
				} else {
					fmt.Printf("   ‚ö†Ô∏è  ARCH MATCH BUT SIZE INCOMPATIBLE: %s (model size doesn't match %d dim mmproj)\n",
						model.Name, mmprojEmbedDim)
					continue
				}
			}

			// 2. Direct basename matching (high confidence)
			if mmprojBasename != "" && modelBasename != "" &&
				strings.EqualFold(mmprojBasename, modelBasename) {
				matches = append(matches, MMProjMatch{
					ModelPath:    model.Path,
					ModelName:    model.Name,
					MMProjPath:   mmprojPath,
					MMProjName:   filepath.Base(mmprojPath),
					MatchType:    "basename",
					Confidence:   0.90,
					MatchDetails: fmt.Sprintf("basename: %s ‚Üí %s", mmprojBasename, modelBasename),
				})
				fmt.Printf("   ‚úÖ BASENAME MATCH: %s (conf: 0.90)\n", model.Name)
				continue
			}

			// 3. Name similarity matching (medium confidence)
			nameSimilarity := calculateNameSimilarity(mmprojName, modelName)
			if nameSimilarity > 0.7 {
				matches = append(matches, MMProjMatch{
					ModelPath:    model.Path,
					ModelName:    model.Name,
					MMProjPath:   mmprojPath,
					MMProjName:   filepath.Base(mmprojPath),
					MatchType:    "name_similarity",
					Confidence:   nameSimilarity,
					MatchDetails: fmt.Sprintf("name similarity: %.2f", nameSimilarity),
				})
				fmt.Printf("   ‚úÖ NAME MATCH: %s (conf: %.2f)\n", model.Name, nameSimilarity)
				continue
			}

			// 4. Base model name similarity (medium confidence)
			if mmprojBaseModelName != "" && modelBaseModelName != "" {
				baseModelSimilarity := calculateNameSimilarity(mmprojBaseModelName, modelBaseModelName)
				if baseModelSimilarity > 0.7 {
					matches = append(matches, MMProjMatch{
						ModelPath:    model.Path,
						ModelName:    model.Name,
						MMProjPath:   mmprojPath,
						MMProjName:   filepath.Base(mmprojPath),
						MatchType:    "base_model_similarity",
						Confidence:   baseModelSimilarity,
						MatchDetails: fmt.Sprintf("base model similarity: %.2f", baseModelSimilarity),
					})
					fmt.Printf("   ‚úÖ BASE MODEL MATCH: %s (conf: %.2f)\n", model.Name, baseModelSimilarity)
					continue
				}
			}
		}
	}

	// Report summary
	fmt.Printf("\nüìä Matching Results:\n")
	if len(matches) == 0 {
		fmt.Printf("   ‚ùå No mmproj matches found\n")
	} else {
		fmt.Printf("   ‚úÖ Found %d mmproj matches:\n", len(matches))
		for i, match := range matches {
			fmt.Printf("   %d. %s ‚Üî %s\n", i+1, match.MMProjName, match.ModelName)
			fmt.Printf("      Type: %s, Confidence: %.2f, Details: %s\n",
				match.MatchType, match.Confidence, match.MatchDetails)
		}
	}

	return matches
}

// getStringValue safely extracts a string value from metadata map
func getStringValue(metadata map[string]interface{}, key string) string {
	if val, exists := metadata[key]; exists {
		if str, ok := val.(string); ok {
			return str
		}
	}
	return ""
}

// calculateNameSimilarity calculates similarity between two names using fuzzy matching
func calculateNameSimilarity(name1, name2 string) float64 {
	if name1 == "" || name2 == "" {
		return 0.0
	}

	// Normalize names for comparison
	norm1 := strings.ToLower(strings.ReplaceAll(name1, "-", " "))
	norm2 := strings.ToLower(strings.ReplaceAll(name2, "-", " "))

	// Exact match
	if norm1 == norm2 {
		return 1.0
	}

	// Contains check (bidirectional)
	if strings.Contains(norm1, norm2) || strings.Contains(norm2, norm1) {
		return 0.8
	}

	// Word-based similarity
	words1 := strings.Fields(norm1)
	words2 := strings.Fields(norm2)

	commonWords := 0
	totalWords := len(words1) + len(words2)

	for _, w1 := range words1 {
		for _, w2 := range words2 {
			if w1 == w2 {
				commonWords++
				break
			}
		}
	}

	if totalWords == 0 {
		return 0.0
	}

	return float64(commonWords*2) / float64(totalWords)
}

// DebugEmbeddingDetection analyzes models to debug embedding detection using GGUF metadata
func DebugEmbeddingDetection(models []ModelInfo) {
	fmt.Printf("\nüîç Debugging embedding model detection using GGUF metadata...\n")

	embeddingModels := []string{}
	chatModels := []string{}
	unknownModels := []string{}

	for _, model := range models {
		if model.IsDraft {
			continue // Skip draft models
		}

		fmt.Printf("\n--- Analyzing: %s ---\n", model.Name)

		// Read GGUF metadata
		metadata, err := ReadAllGGUFKeys(model.Path)
		if err != nil {
			fmt.Printf("‚ùå Failed to read metadata: %v\n", err)
			unknownModels = append(unknownModels, model.Name)
			continue
		}

		// Extract key fields for embedding detection
		architecture := getStringValue(metadata, "general.architecture")
		modelType := getStringValue(metadata, "tokenizer.ggml.model")
		contextLength := getIntValue(metadata, fmt.Sprintf("%s.context_length", architecture))
		embeddingLength := getIntValue(metadata, fmt.Sprintf("%s.embedding_length", architecture))
		poolingType := getStringValue(metadata, fmt.Sprintf("%s.pooling_type", architecture))
		hasRope := hasKey(metadata, fmt.Sprintf("%s.rope", architecture))
		hasHeadCount := hasKey(metadata, fmt.Sprintf("%s.head_count", architecture))

		fmt.Printf("   üìã Metadata Analysis:\n")
		fmt.Printf("      Architecture: %s\n", architecture)
		fmt.Printf("      Model Type: %s\n", modelType)
		fmt.Printf("      Context Length: %d\n", contextLength)
		fmt.Printf("      Embedding Length: %d\n", embeddingLength)
		fmt.Printf("      Pooling Type: %s\n", poolingType)
		fmt.Printf("      Has RoPE: %t\n", hasRope)
		fmt.Printf("      Has Head Count: %t\n", hasHeadCount)

		// Apply embedding detection logic (pass filename too for better detection)
		isEmbedding := detectEmbeddingFromMetadata(metadata, architecture, model.Name)
		currentlyDetectedAsEmbedding := strings.Contains(strings.ToLower(model.Name), "embed")

		fmt.Printf("   üéØ Detection Results:\n")
		fmt.Printf("      New Algorithm: %s\n", boolToEmoji(isEmbedding))
		fmt.Printf("      Current Algorithm: %s\n", boolToEmoji(currentlyDetectedAsEmbedding))

		if isEmbedding != currentlyDetectedAsEmbedding {
			fmt.Printf("   ‚ö†Ô∏è  MISMATCH DETECTED!\n")
		}

		if isEmbedding {
			embeddingModels = append(embeddingModels, model.Name)
		} else {
			chatModels = append(chatModels, model.Name)
		}
	}

	// Summary
	fmt.Printf("\nüìä Detection Summary:\n")
	fmt.Printf("   üìù Embedding Models (%d):\n", len(embeddingModels))
	for _, name := range embeddingModels {
		fmt.Printf("      - %s\n", name)
	}
	fmt.Printf("   üí¨ Chat Models (%d):\n", len(chatModels))
	for _, name := range chatModels {
		fmt.Printf("      - %s\n", name)
	}
	if len(unknownModels) > 0 {
		fmt.Printf("   ‚ùì Unknown Models (%d):\n", len(unknownModels))
		for _, name := range unknownModels {
			fmt.Printf("      - %s\n", name)
		}
	}
}

// detectEmbeddingFromMetadata uses comprehensive GGUF metadata to detect embedding models
func detectEmbeddingFromMetadata(metadata map[string]interface{}, architecture string, filename string) bool {
	// Get model name from metadata AND filename for checks
	metadataName := getStringValue(metadata, "general.name")
	archLower := strings.ToLower(architecture)

	// Check BOTH metadata name AND filename
	lowerMetadataName := strings.ToLower(metadataName)
	lowerFilename := strings.ToLower(filename)

	// PRIORITY 1: Name-based check (HIGHEST PRIORITY - trust explicit naming)
	// Check BOTH metadata name AND filename - if either explicitly says "embed" or "embedding", trust it!
	if strings.Contains(lowerMetadataName, "embed") ||
		strings.Contains(lowerMetadataName, "embedding") ||
		strings.Contains(lowerFilename, "embed") ||
		strings.Contains(lowerFilename, "embedding") ||
		strings.HasPrefix(lowerMetadataName, "e5-") ||
		strings.HasPrefix(lowerFilename, "e5-") ||
		strings.HasPrefix(lowerMetadataName, "bge-") ||
		strings.HasPrefix(lowerFilename, "bge-") ||
		strings.HasPrefix(lowerMetadataName, "gte-") ||
		strings.HasPrefix(lowerFilename, "gte-") ||
		strings.Contains(lowerMetadataName, "minilm") ||
		strings.Contains(lowerFilename, "minilm") ||
		strings.Contains(lowerMetadataName, "mxbai") ||
		strings.Contains(lowerFilename, "mxbai") {
		return true
	}

	// PRIORITY 2: Check pooling_type metadata (VERY RELIABLE for models without explicit names)
	// Embedding models have pooling_type set to: mean, cls, last, rank
	// Language models have NO pooling_type or pooling_type = "none"
	poolingType := getStringValue(metadata, fmt.Sprintf("%s.pooling_type", architecture))
	if poolingType != "" && poolingType != "none" {
		// If pooling_type exists and is not "none", it's definitely an embedding model
		return true
	}

	// PRIORITY 3: Architecture check - BERT-based models are embeddings
	switch archLower {
	case "bert", "roberta", "nomic-bert", "jina-bert":
		return true
	case "llama", "mistral", "gemma", "gemma3", "glm4moe", "seed_oss", "gpt-oss":
		// These are typically generative models
		return false
	}

	// PRIORITY 4: Exclude Vision-Language models (only if name didn't indicate embedding)
	// This comes AFTER name check so models explicitly named "embedding" still pass through
	if archLower == "qwen2vl" || archLower == "llava" || strings.Contains(archLower, "vision") {
		return false
	}

	// PRIORITY 4: Tokenizer model check - BERT tokenizers indicate embeddings
	tokenizerModel := getStringValue(metadata, "tokenizer.ggml.model")
	if strings.Contains(strings.ToLower(tokenizerModel), "bert") {
		return true
	}

	// PRIORITY 5: Missing chat model keys + small embedding dimensions
	embeddingLength := getIntValue(metadata, fmt.Sprintf("%s.embedding_length", architecture))
	hasRope := hasKey(metadata, fmt.Sprintf("%s.rope", architecture))
	hasHeadCount := hasKey(metadata, fmt.Sprintf("%s.head_count", architecture))

	// Chat models typically have RoPE and head_count, embedding models often don't
	if !hasRope && !hasHeadCount && embeddingLength > 0 && embeddingLength <= 1024 {
		return true
	}

	// Default to chat model if no clear embedding indicators
	return false
}

// Helper functions for metadata analysis
func getIntValue(metadata map[string]interface{}, key string) int {
	if val, exists := metadata[key]; exists {
		switch v := val.(type) {
		case int:
			return v
		case int32:
			return int(v)
		case int64:
			return int(v)
		case float64:
			return int(v)
		case float32:
			return int(v)
		case uint32:
			return int(v)
		case uint64:
			return int(v)
		}
	}
	return 0
}

func hasKey(metadata map[string]interface{}, keyPrefix string) bool {
	for key := range metadata {
		if strings.HasPrefix(strings.ToLower(key), strings.ToLower(keyPrefix)) {
			return true
		}
	}
	return false
}

func boolToEmoji(b bool) string {
	if b {
		return "‚úÖ Embedding"
	}
	return "üí¨ Chat"
}

// isModelNameCompatibleWithMMProj checks if model name suggests compatibility with mmproj projection dimension
func isModelNameCompatibleWithMMProj(modelName string, mmprojEmbedDim int) bool {
	lowerName := strings.ToLower(modelName)

	// Extract size indicators from model name
	if strings.Contains(lowerName, "27b") || strings.Contains(lowerName, "22b") || strings.Contains(lowerName, "30b") {
		// Large models - should work with 5376 dimension mmproj
		return mmprojEmbedDim == 5376
	}

	if strings.Contains(lowerName, "9b") || strings.Contains(lowerName, "8b") || strings.Contains(lowerName, "7b") {
		// Medium models - should work with 3584 dimension mmproj
		return mmprojEmbedDim == 3584
	}

	if strings.Contains(lowerName, "4b") || strings.Contains(lowerName, "3b") || strings.Contains(lowerName, "2b") {
		// Small models - should work with 2560 dimension mmproj
		return mmprojEmbedDim == 2560
	}

	// Special cases for models with size indicators
	if strings.Contains(lowerName, "1b") || strings.Contains(lowerName, "0.6b") || strings.Contains(lowerName, "0.5b") {
		// Very small models - likely compatible with smaller mmproj
		return mmprojEmbedDim <= 2560
	}

	// If we can't determine size from name, check for other patterns
	// InternVL, LLaVA, etc. might have different naming conventions
	if strings.Contains(lowerName, "14b") {
		// 14B models often use 5120 projection dimension
		return mmprojEmbedDim == 5120 || mmprojEmbedDim == 5376
	}

	// For unknown sizes, be more permissive but still check for obvious mismatches
	// Don't match very large mmproj (5376) with obviously small model names
	if mmprojEmbedDim == 5376 && (strings.Contains(lowerName, "nano") || strings.Contains(lowerName, "tiny") || strings.Contains(lowerName, "mini")) {
		return false
	}

	// Default to allowing the match if we can't determine incompatibility
	return true
}

// getSystemRAM returns total system RAM in GB
func getSystemRAM() float64 {
	// Try to get actual RAM from /proc/meminfo on Linux
	if runtime.GOOS == "linux" {
		data, err := os.ReadFile("/proc/meminfo")
		if err == nil {
			lines := strings.Split(string(data), "\n")
			for _, line := range lines {
				if strings.HasPrefix(line, "MemTotal:") {
					parts := strings.Fields(line)
					if len(parts) >= 2 {
						if memKB, err := strconv.ParseFloat(parts[1], 64); err == nil {
							return memKB / (1024 * 1024) // Convert KB to GB
						}
					}
				}
			}
		}
	}

	// Default fallback - estimate based on OS
	switch runtime.GOOS {
	case "windows", "linux":
		return 16.0 // Conservative default
	case "darwin":
		return 8.0 // Mac default
	default:
		return 8.0
	}
}
